{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd3a233",
   "metadata": {},
   "source": [
    "\n",
    "### Report on Movie Genre Prediction Experiment Design\n",
    "\n",
    "#### Step 1: Methodology for determining movie genre label codebook \n",
    "I have used various databases such as IMDB and TMDB to shortlist genres. Links are given in the end of this file.\n",
    "\n",
    "#### Step 2: Methodology for labelling of a large scale dataset \n",
    "##### Step 2.1: Preprocessing\n",
    "**Purpose:**\n",
    "To download youtube audio from videos using yt-dlp in 1-VideoToAudio NoteBook. Then the audios are transcribed using whiper ASR and stored in a new directory, this is done in 2-AddToDriveAndTranscribe NoteBook. And lastly, the transcribed files are renamed to remove any special characters since it was created an issue while zipping, this is done in 3-SanitizeFileNames Notebook.\n",
    "\n",
    "I have worked on a dataset of 140 files due to laptop compatability issues.\n",
    "\n",
    "Rest of the working is in 4-SVM and 5-RandomForest Notebooks.\n",
    "\n",
    "##### Step 2.2: Tokenize the Audio Text Files\n",
    "**Purpose:**\n",
    "To preprocess the text data by tokenizing the audio transcripts. This involves:\n",
    "- Reading text files from a specified directory.\n",
    "- Tokenizing the text using NLTK's `RegexpTokenizer` to split the text into individual words while removing punctuation.\n",
    "- Removing stop words to reduce noise in the data.\n",
    "- Saving the processed tokens into new text files in a separate directory.\n",
    "- Renaming the files to remove special characters.\n",
    "- Creating a CSV file that includes the filename, tokens, and genre columns.\n",
    "\n",
    "##### Step 2.3: Assign Labels Using BERT Embedding, K-Means, and Genre Keywords\n",
    "**Purpose:**\n",
    "To automatically assign genres to the processed text data using advanced techniques. This involves:\n",
    "- Using BERT embeddings to convert the text data into high-dimensional vectors that capture the semantic meaning.\n",
    "- Applying K-Means clustering to group similar text data together.\n",
    "- Utilizing a predefined set of genre keywords to help label the clusters based on the presence of these keywords in the text.\n",
    "\n",
    "##### Step 2.4: TF-IDF Vectorization\n",
    "**Purpose:**\n",
    "To transform the tokenized text data into numerical features that can be used for machine learning models. This involves:\n",
    "- Using `TfidfVectorizer` to convert the text data into TF-IDF (Term Frequency-Inverse Document Frequency) features, which highlight important words in the documents while reducing the influence of common but less informative words. \n",
    "\n",
    "It is used after step 3 to increase the accuracy of the model.\n",
    "\n",
    "#### Step 3: Partitioning methodology \n",
    "**Purpose:**\n",
    "To divide the dataset into two parts: one for training the machine learning model and one for evaluating its performance. This step involves:\n",
    "- Using `train_test_split` from Scikit-learn to split the data while maintaining the class distribution (stratified sampling).\n",
    "- Ensuring that the training set is used to build the model and the testing set is used to assess how well the model generalizes to unseen data.\n",
    "- Train-to-Test Ratio:\n",
    "    Training Set: 80%\n",
    "    Testing Set: 20%\n",
    "- This means if i have 140 instances in the dataset:\n",
    "    Training Instances: 140 * 0.8 = 112\n",
    "    Testing Instances: 140 * 0.2 = 28\n",
    "\n",
    "#### Step 4: Modelling approach\n",
    "**Purpose:**\n",
    "To train the model on the labeled partitioned dataset created in last step, for movie genre prediction.\n",
    "- SVM classifier and random forest have been used seperately for training, both of these give different results.\n",
    "- Used Grid Search to find the best hyperparameters for both models.\n",
    "\n",
    "#### Step 5: Experimental protocol and performance metric calculation\n",
    "**Purpose:**\n",
    "To evaluate the accuracy of the trained model:\n",
    "- Evaluated the model on precision recall f1-score support.\n",
    "\n",
    "### References\n",
    "For Genre Selection:\n",
    "- https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows\n",
    "- https://www.kaggle.com/datasets/rajugc/imdb-movies-dataset-based-on-genre\n",
    "- https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata\n",
    "- https://zenodo.org/records/7339445\n",
    "\n",
    "For Transcription:\n",
    "- https://www.youtube.com/watch?v=3_2McMS4wNM\n",
    "\n",
    "For Model:\n",
    "- https://medium.com/@gabya06/predicting-movie-genres-using-machine-learning-models-and-semantic-textual-similarity-f77a5e842a89\n",
    "- https://link.springer.com/chapter/10.1007/978-3-642-35236-2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896e0f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
